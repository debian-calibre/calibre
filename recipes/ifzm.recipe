from calibre.web.feeds.news import BasicNewsRecipe
import json

def json_to_html(raw, link):
    data = json.loads(raw)
    data = data['data']['content']
    title = '<h1 title="{}">'.format(link) + data['subject'] + '</h1>'
    auth = '<p><b>' + data['author'] + '</b></p>'
    sub = '<p class="intro"><i>' + data['introtext'] + '</i></p>'
    body = data['fulltext']
    return '<html><body><div>' + title + auth + sub + body + '</div></body></html>'


class infzm(BasicNewsRecipe):
    title = '南方周末'
    __author__ = 'unkn0wn'
    description = 'Southern Weekly (infzm.com), founded in 1984, is a Chinese weekly newspaper based in Guangzhou. Download Weekly.'
    language = 'zh'
    encoding = 'utf-8'
    no_stylesheets = True
    remove_javascript = True
    ignore_duplicate_articles = {'title'}
    remove_empty_feeds = True
    use_embedded_content = False
    remove_attributes = ['style', 'height', 'width']
    masthead_url = 'http://ssimg.kkod.cn/web/02/14227.gif'

    articles_are_obfuscated = True

    remove_tags = [dict(name=['video', 'svg', 'button'])]

    def get_obfuscated_article(self, url):
        br = self.get_browser()
        try:
            br.open(url)
        except Exception as e:
            url = e.hdrs.get('location')
        soup = self.index_to_soup(url)
        link = soup.find('a', href=True)['href'].split('?')[0]
        res_link = link.replace('https://www.infzm.com', 'https://api.infzm.com/mobile') \
            + '?platform=wap&version=1.89.0&machine_id=35458aa29603f2b246636e5492122b50&user_id=&token=&member_type='
        # if article is paywalled, add code to figure out machine_id
        raw = br.open(res_link).read()
        html = json_to_html(raw, link)
        return ({ 'data': html, 'url': link })

    extra_css = '''
        img {display:block; margin:0 auto;}
        .cm_pic_caption, .cm_pic_author { font-size:small; text-align:center; }
    '''

    feeds = [
        ('南方周末', 'https://news.google.com/rss/search?q=when:170h+allinurl:https%3A%2F%2Fwww.infzm.com&hl=zh-HK&gl=HK&ceid=HK:zh')
    ]

    def populate_article_metadata(self, article, soup, first):
        article.title = article.title.replace(' - 南方周末', '')
        article.url = soup.find('h1')['title']
        article.summary = self.tag_to_string(soup.find(attrs={'class':'intro'}))
        article.text_summary = self.tag_to_string(soup.find(attrs={'class':'intro'}))
