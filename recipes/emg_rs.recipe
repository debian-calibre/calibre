__license__   = 'GPL v3'
__copyright__ = '2010, Darko Miletic <darko.miletic at gmail.com>'
'''
emg.rs/vesti
'''

import re
from calibre.web.feeds.news import BasicNewsRecipe

class emportal_rs(BasicNewsRecipe):
    title                 = 'Ekonom:east Vesti'
    __author__            = 'Darko Miletic'
    description           = 'Vasa dnevna doza poslovnih informacija iz Srbije, regiona i sveta. Vesti, Berze, Dogadaji, Casopisi.'
    publisher             = 'Ekonom:east Media Group'
    category              = 'Ekonom:east Media Group, Ekonomist, Budelar, Bankar, EMportal, Preduzeca, Moja Posla, EU praktikum, ekonomija, Srbija, Beograd, investicije, finansije, energetika, berza'
    oldest_article        = 2
    max_articles_per_feed = 200
    no_stylesheets        = True
    encoding              = 'utf8'
    use_embedded_content  = False
    language              = 'sr'
    remove_empty_feeds    = True
    masthead_url          = 'http://www.emg.rs/img/emportal-rss.png'
    extra_css             = ' @font-face {font-family: "sans1";src:url(res:///opt/sony/ebook/FONT/tt0003m_.ttf)} body{font-family: Arial,Helvetica,sans1,sans-serif } .article_description{font-family: sans1, sans-serif} '

    conversion_options = {
                          'comment'   : description
                        , 'tags'      : category
                        , 'publisher' : publisher
                        , 'language'  : language
                        }

    preprocess_regexps = [(re.compile(u'\u0110'), lambda match: u'\u00D0')]
    remove_tags        = [dict(attrs={'class':['text-share']})]
    keep_only_tags     = [dict(attrs={'class':'text'})]
    remove_tags_after  = dict(attrs={'class':'text-share'})
    remove_attributes  = ['width','height']

    feeds = [
              (u'Srbija' , u'http://www.emg.rs/vesti/srbija/rss.xml')
             ,(u'Region' , u'http://www.emg.rs/vesti/region/rss.xml')
             ,(u'Svet'   , u'http://www.emg.rs/vesti/svet/rss.xml'  )
            ]

    def print_version(self, url):
        return url.replace('.html','.print.html')

    def preprocess_html(self, soup):
        for item in soup.findAll(style=True):
            del item['style']
        return soup
