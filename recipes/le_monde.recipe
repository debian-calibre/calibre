#!/usr/bin/env python
# vim:fileencoding=utf-8
from __future__ import absolute_import, division, print_function, unicode_literals

__license__ = 'GPL v3'
__copyright__ = '2012'

'''
lemonde.fr
'''

from calibre.web.feeds.news import BasicNewsRecipe, classes
from datetime import date
import re


class LeMonde(BasicNewsRecipe):
    title = 'Le Monde'
    __author__ = 'veezh'
    description = 'Les flux RSS du Monde.fr'
    publisher = 'Société Editrice du Monde'
    publication_type = 'newspaper'
    needs_subscription = 'optional'
    language = 'fr'

    oldest_article = 2
    max_articles_per_feed = 15
    no_stylesheets = True
    remove_empty_feeds = True
    ignore_duplicate_articles = {'title', 'url'}

    conversion_options = {
        'publisher': publisher
    }

    masthead_url = 'http://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Le_monde_logo.svg/800px-Le_monde_logo.svg.png'

    feeds = [
        ('A la une', 'https://www.lemonde.fr/rss/une.xml'),
        ('International', 'https://www.lemonde.fr/international/rss_full.xml'),
        ('Politique', 'https://www.lemonde.fr/politique/rss_full.xml'),
        ('Société', 'https://www.lemonde.fr/societe/rss_full.xml'),
        ('Economie', 'https://www.lemonde.fr/economie/rss_full.xml'),
        ('Planète', 'https://www.lemonde.fr/planete/rss_full.xml'),
        ('Sciences', 'https://www.lemonde.fr/sciences/rss_full.xml'),
        ('Pixels', 'https://www.lemonde.fr/pixels/rss_full.xml'),
        ('Culture', 'https://www.lemonde.fr/culture/rss_full.xml'),
        ('Idées', 'https://www.lemonde.fr/idees/rss_full.xml')
    ]

    keep_only_tags = [
        classes('article__header'),
        dict(name='section', attrs={'class': ['article__content', 'article__heading',
                                              'article__wrapper']})
    ]

    remove_tags = [
        classes('article__status meta__date meta__reading-time meta__social multimedia-embed'),
        dict(name=['footer', 'link']),
        dict(name='img', attrs={'class': ['article__author-picture']}),
        dict(name='section', attrs={'class': ['article__reactions', 'author', 'catcher',
                                              'portfolio', 'services-inread']})
    ]

    remove_attributes = [
        'data-sizes', 'height', 'sizes', 'width'
    ]

    preprocess_regexps = [
        # insert space between author name and description
        (re.compile(r'(<span class="[^"]*author__desc[^>]*>)([^<]*</span>)',
                    re.IGNORECASE), lambda match: match.group(1) + ' ' + match.group(2)),
        # insert " | " between article type and description
        (re.compile(r'(<span class="[^"]*article__kicker[^>]*>[^<]*)(</span>)',
                    re.IGNORECASE), lambda match: match.group(1) + ' | ' + match.group(2))
    ]

    extra_css = '''
        h2 { font-size: 1em; }
        h3 { font-size: 1em; }
        .article__desc { font-weight: bold; }
        .article__fact { font-weight: bold; text-transform: uppercase; }
        .article__kicker { text-transform: uppercase; }
        .article__legend { font-size: 0.6em; margin-bottom: 1em; }
        .article__title { margin-top: 0em; }
    '''

    def get_browser(self):
        br = BasicNewsRecipe.get_browser(self)
        if self.username is not None and self.password is not None:
            try:
                br.open('https://secure.lemonde.fr/sfuser/connexion')
                br.select_form(nr=0)
                br['email'] = self.username
                br['password'] = self.password
                br.submit()
            except Exception as e:
                self.log('Login failed with error:', str(e))
        return br

    def get_cover_url(self):
        # today's date is a reasonable guess for the ID of the cover
        cover_id = date.today().strftime('%Y%m%d')
        soup = self.index_to_soup('https://www.lemonde.fr/')
        a = soup.find('a', {'id': 'jelec_link', 'style': True})
        if a and a['style']:
            url = a['style'].split('/')
            if len(url) > 5 and url[3].isdigit():
                # overwrite guess if actual cover ID was found
                cover_id = url[3]
        return 'https://www.lemonde.fr/thumbnail/journal/' + cover_id + '/1000/1490'

    def get_article_url(self, article):
        url = BasicNewsRecipe.get_article_url(self, article)
        # skip articles without relevant content (e.g., videos)
        for el in 'blog chat live podcasts portfolio video visuel'.split():
            if '/' + el + '/' in url:
                self.log('Skipping URL', url)
                self.abort_article()
        return url

    def preprocess_html(self, soup):
        # when an image is available in multiple sizes, select the smallest one
        for img in soup.find_all('img', {'data-srcset': True}):
            data_srcset = img['data-srcset'].split()
            if len(data_srcset) > 1:
                img['src'] = data_srcset[-2]
                del img['data-srcset']
        return soup

    def postprocess_html(self, soup, first_fetch):
        # remove local hyperlinks
        for a in soup.find_all('a', {'href': True}):
            if '.lemonde.fr/' in a['href']:
                a.replace_with(self.tag_to_string(a))
        # clean up header
        for ul in soup.find_all('ul', {'class': 'breadcrumb'}):
            div = soup.new_tag('div')
            category = ''
            for li in ul.find_all('li', {'class': True}):
                category += self.tag_to_string(li).strip().upper() + ' - '
                div.string = category[:-3]
            ul.replace_with(div)
        return soup
