__license__ = 'GPL v3'
__copyright__ = '2010-2012, Louis Gesbert <meta at antislash dot info>'
'''
Rue89
'''

__author__ = '2010-2012, Louis Gesbert <meta at antislash dot info>'

import re
from calibre.web.feeds.news import BasicNewsRecipe


class Rue89(BasicNewsRecipe):
    title = 'Rue89'
    __author__ = 'Louis Gesbert'
    description = 'Popular free french news website'
    title = u'Rue89'
    language = 'fr'
    oldest_article = 7
    max_articles_per_feed = 50

    use_embedded_content = False

    # From http://www.rue89.com/les-flux-rss-de-rue89
    feeds = [
        (u'La Une',    u'http://www.rue89.com/feed'),
        # Other feeds disabled, 'La Une' seems to include them all
        # (u'Rue69',     u'http://www.rue89.com/rue69/feed'),
        # (u'Eco',       u'http://www.rue89.com/rue89-eco/feed'),
        # (u'Plan√®te',   u'http://www.rue89.com/rue89-planete/feed'),
        # (u'Sport',     u'http://www.rue89.com/rue89-sport/feed'),
        # (u'Culture',   u'http://www.rue89.com/culture/feed'),
        # (u'Hi-tech',   u'http://www.rue89.com/hi-tech/feed'),
        # (u'Media',     u'http://www.rue89.com/medias/feed'),
        # (u'Monde',     u'http://www.rue89.com/monde/feed'),
        # (u'Politique', u'http://www.rue89.com/politique/feed'),
        # (u'Societe',   u'http://www.rue89.com/societe/feed'),
    ]

    # Follow redirection from feedsportal.com
    def get_article_url(self, article):
        return self.browser.open_novisit(article.link).geturl()

    def print_version(self, url):
        return url + '?imprimer=1'

    conversion_options = {'smarten_punctuation': True}

    keep_only_tags = [
        dict(name='div', attrs={'id': 'content'}),
    ]

    remove_tags_after = [
        dict(name='div', attrs={'id': 'plus_loin'}),
        dict(name='div', attrs={'class': 'stats'}),
    ]

    remove_tags = [
        dict(name='div', attrs={'id': 'article_tools'}),
        dict(name='div', attrs={'id': 'plus_loin'}),
        dict(name='div', attrs={'class': 'stats'}),
        dict(name='div', attrs={'class': 'tools'}),
    ]

    extra_css = "#content { padding: 0 0; }"

    # Without this, parsing of video articles returns strange results
    preprocess_regexps = [
        (re.compile(r'<script.*?</script>', re.IGNORECASE | re.DOTALL), ''),
    ]

    def preprocess_html(self, soup):
        # Remove whole article if it's a "zapnet" (video)
        if soup.find('h1', {'class': 'zapnet_title'}):
            return None
        # Reduce h2 titles to h3
        for title in soup.findAll('h2'):
            title.name = 'h3'
        return soup
